{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "In this assignment, you'll continue working with the house prices data. To complete this assignment, submit a link to a Jupyter notebook containing your solutions to the following tasks:\n",
    "\n",
    "* Load the **houseprices** data from Thinkful's database.\n",
    "* Reimplement your model from the previous checkpoint.\n",
    "* Try OLS, Lasso, Ridge, and ElasticNet regression using the same model specification. This time, you need to do **k-fold cross-validation** to choose the best hyperparameter values for your models. Scikit-learn has RidgeCV, LassoCV, and ElasticNetCV that you can utilize to do this. Which model is the best? Why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "from sklearn.linear_model import (LinearRegression, ElasticNet, Lasso, Ridge, RidgeCV, LassoCV, ElasticNetCV)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "\n",
    "sns.set_style('dark')\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'houseprices'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "hp_df = pd.read_sql_query('select * from houseprices',con=engine, index_col='id')\n",
    "\n",
    "# no need for an open connection, as we're only doing a single query\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total home sq ft\n",
    "hp_df['totalsqft'] = hp_df.totalbsmtsf + hp_df.firstflrsf + hp_df.secondflrsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# current model\n",
    "\n",
    "# adjusting target to log(x+1)\n",
    "y = np.log1p(hp_df.saleprice)\n",
    "\n",
    "# choosing categories based on a Random Forest Regression I ran in another notebook\n",
    "X = hp_df[['garagecars', 'overallqual', 'totalsqft']] \n",
    "\n",
    "# Splitting up train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              saleprice   R-squared:                       0.816\n",
      "Model:                            OLS   Adj. R-squared:                  0.815\n",
      "Method:                 Least Squares   F-statistic:                     1720.\n",
      "Date:                Thu, 19 Mar 2020   Prob (F-statistic):               0.00\n",
      "Time:                        20:51:13   Log-Likelihood:                 403.28\n",
      "No. Observations:                1168   AIC:                            -798.6\n",
      "Df Residuals:                    1164   BIC:                            -778.3\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const          10.5421      0.023    454.624      0.000      10.497      10.588\n",
      "garagecars      0.1096      0.009     12.252      0.000       0.092       0.127\n",
      "overallqual     0.1200      0.005     22.301      0.000       0.109       0.131\n",
      "totalsqft       0.0002   9.06e-06     23.874      0.000       0.000       0.000\n",
      "==============================================================================\n",
      "Omnibus:                      499.490   Durbin-Watson:                   1.980\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5046.053\n",
      "Skew:                          -1.696   Prob(JB):                         0.00\n",
      "Kurtosis:                      12.601   Cond. No.                     1.25e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.25e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "# adding constant\n",
    "X_train = sm.add_constant(X_train)\n",
    "\n",
    "results = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              saleprice   R-squared:                       0.748\n",
      "Model:                            OLS   Adj. R-squared:                  0.745\n",
      "Method:                 Least Squares   F-statistic:                     284.9\n",
      "Date:                Thu, 19 Mar 2020   Prob (F-statistic):           7.54e-86\n",
      "Time:                        21:38:20   Log-Likelihood:                 55.130\n",
      "No. Observations:                 292   AIC:                            -102.3\n",
      "Df Residuals:                     288   BIC:                            -87.55\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const          10.6892      0.051    208.290      0.000      10.588      10.790\n",
      "garagecars      0.1224      0.018      6.718      0.000       0.087       0.158\n",
      "overallqual     0.1466      0.012     12.461      0.000       0.123       0.170\n",
      "totalsqft    8.934e-05   1.62e-05      5.527      0.000    5.75e-05       0.000\n",
      "==============================================================================\n",
      "Omnibus:                      136.241   Durbin-Watson:                   2.042\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1458.600\n",
      "Skew:                          -1.601   Prob(JB):                         0.00\n",
      "Kurtosis:                      13.471   Cond. No.                     1.21e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.21e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Add constant to X Test too!\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "results = sm.OLS(y_test, X_test).fit()\n",
    "\n",
    "print(results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best alpha value is: 10.0\n",
      "R-squared of the model on the training set is: 0.8159309108448491\n",
      "-----Test set statistics-----\n",
      "R-squared of the model on the test set is: 0.6845628966881296\n",
      "Mean absolute error of the prediction is: 0.13\n",
      "Mean squared error of the prediction is: 0.05\n",
      "Root mean squared error of the prediction is: 0.0\n",
      "Mean absolute percentage error of the prediction is: 1.12\n"
     ]
    }
   ],
   "source": [
    "alphas = [np.power(10.0,p) for p in np.arange(-10,40,1)]\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_rgr = RidgeCV(alphas=alphas, cv=5)\n",
    "ridge_rgr.fit(X_train, y_train)\n",
    "\n",
    "y_preds = ridge_rgr.predict(X_test)\n",
    "\n",
    "print(f\"The best alpha value is: {ridge_rgr.alpha_}\")\n",
    "print(f\"R-squared of the model on the training set is: {ridge_rgr.score(X_train, y_train)}\")\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(f\"R-squared of the model on the test set is: {ridge_rgr.score(X_test, y_test)}\")\n",
    "print(f\"Mean absolute error of the prediction is: {round(mean_absolute_error(y_test, y_preds), 2)}\")\n",
    "print(f\"Mean squared error of the prediction is: {round(mse(y_test, y_preds),2)}\")\n",
    "print(f\"Root mean squared error of the prediction is: {round(rmse(y_test, y_preds))}\")\n",
    "print(f\"Mean absolute percentage error of the prediction is: {round(np.mean(np.abs((y_test - y_preds) / y_test) * 100),2)}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best alpha value is: 0.0001\n",
      "R-squared of the model on the training set is: 0.8159467570960331\n",
      "-----Test set statistics-----\n",
      "R-squared of the model on the test set is: 0.6856341188855839\n",
      "Mean absolute error of the prediction is: 0.13\n",
      "Mean squared error of the prediction is: 0.05\n",
      "Root mean squared error of the prediction is: 0.0\n",
      "Mean absolute percentage error of the prediction is: 1.12\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "LASSO_rgr = LassoCV(alphas=alphas, cv=5)\n",
    "LASSO_rgr.fit(X_train, y_train)\n",
    "\n",
    "y_preds = LASSO_rgr.predict(X_test)\n",
    "\n",
    "print(f\"The best alpha value is: {LASSO_rgr.alpha_}\")\n",
    "print(f\"R-squared of the model on the training set is: {LASSO_rgr.score(X_train, y_train)}\")\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(f\"R-squared of the model on the test set is: {LASSO_rgr.score(X_test, y_test)}\")\n",
    "print(f\"Mean absolute error of the prediction is: {round(mean_absolute_error(y_test, y_preds), 2)}\")\n",
    "print(f\"Mean squared error of the prediction is: {round(mse(y_test, y_preds),2)}\")\n",
    "print(f\"Root mean squared error of the prediction is: {round(rmse(y_test, y_preds))}\")\n",
    "print(f\"Mean absolute percentage error of the prediction is: {round(np.mean(np.abs((y_test - y_preds) / y_test) * 100),2)}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best alpha value is: 0.001\n",
      "R-squared of the model on the training set is: 0.815941286733658\n",
      "-----Test set statistics-----\n",
      "R-squared of the model on the test set is: 0.6850689330060431\n",
      "Mean absolute error of the prediction is: 0.13\n",
      "Mean squared error of the prediction is: 0.05\n",
      "Root mean squared error of the prediction is: 0.0\n",
      "Mean absolute percentage error of the prediction is: 1.12\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "ElasticNet_rgr = ElasticNetCV(alphas=alphas, cv=5)\n",
    "ElasticNet_rgr.fit(X_train, y_train)\n",
    "\n",
    "y_preds = ElasticNet_rgr.predict(X_test)\n",
    "\n",
    "print(f\"The best alpha value is: {ElasticNet_rgr.alpha_}\")\n",
    "print(f\"R-squared of the model on the training set is: {ElasticNet_rgr.score(X_train, y_train)}\")\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(f\"R-squared of the model on the test set is: {ElasticNet_rgr.score(X_test, y_test)}\")\n",
    "print(f\"Mean absolute error of the prediction is: {round(mean_absolute_error(y_test, y_preds), 2)}\")\n",
    "print(f\"Mean squared error of the prediction is: {round(mse(y_test, y_preds),2)}\")\n",
    "print(f\"Root mean squared error of the prediction is: {round(rmse(y_test, y_preds))}\")\n",
    "print(f\"Mean absolute percentage error of the prediction is: {round(np.mean(np.abs((y_test - y_preds) / y_test) * 100),2)}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks as though OLS was the best version"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonenv",
   "language": "python",
   "name": "pythonenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
