{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "36.6 Challenge.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP5Ls90SWKHyKadz2m/EP3J"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWARGdfX5g9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense, LeakyReLU\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import losses, optimizers\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nT8NBdnXz1od",
        "colab_type": "text"
      },
      "source": [
        "# Challenge\n",
        "In this module, we introduced the basics of deep learning and the fundamental architecture of the artificial neural networks. During the examples in the checkpoints, we used a MNIST dataset. In this challenge, you'll work with another dataset called fashion MNIST. Using this dataset, you need to:\n",
        "\n",
        "1. Preprocess your data so that you can feed it into ANN models.\n",
        "2. Split your data into training and test sets.\n",
        "Try different ANN models and train them on your training set. You can play with: \n",
        "  * 3.1. Number of layers.\n",
        "  * 3.2. Activation functions of the layers.\n",
        "  * 3.3. Number of neurons in the layers.\n",
        "  * 3.4. Different batch sizes during training.\n",
        "\n",
        "3. Compare your models' training scores and interpret your results.\n",
        "4. Evaluate your models' performances on your test set. Compare the results of your models.\n",
        "\n",
        "Please submit your solutions to the following tasks as a link to your Jupyter notebook on GitHub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLJ5LonBLzEc",
        "colab_type": "text"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_JiE8o9Dq5m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "7a5a47b6-9db6-416c-dfd7-6827ce2953b0"
      },
      "source": [
        "# Loading data and preprocessing\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIaT8KiHD6Ye",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "bcbf58d7-db1f-45cb-f9b4-337bd155cfe2"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFbLD0faL24W",
        "colab_type": "text"
      },
      "source": [
        "### Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STm9kKNe8BKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = 784  # 28*28\n",
        "output_dim = nb_classes = 10\n",
        "batch_size = 128\n",
        "nb_epoch = 20\n",
        "\n",
        "X_train = X_train.reshape(60000, input_dim)\n",
        "X_test = X_test.reshape(10000, input_dim)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW3jJeFd8Gf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hot encoding through Keras\n",
        "Y_train_hot = to_categorical(y_train, nb_classes)\n",
        "Y_test_hot = to_categorical(y_test, nb_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOHijoec8bCu",
        "colab_type": "code",
        "outputId": "2370fbc9-2deb-44fd-e1bb-606211e9ccc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Checking the size of the data\n",
        "X_train[0].shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUz5fmTvL5XR",
        "colab_type": "text"
      },
      "source": [
        "### Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlCQXMR-K6V1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "e8dbe468-fd08-4e1d-f80a-f46037002b1f"
      },
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "plt.style.use('dark_background')\n",
        "\n",
        "plt.subplot(141)\n",
        "plt.imshow(X_train[10].reshape(28,28), cmap=\"gray\")\n",
        "plt.title(\"Label of the image: {}\".format(y_train[10]))\n",
        "\n",
        "plt.subplot(142)\n",
        "plt.imshow(X_train[11].reshape(28,28), cmap=\"gray\")\n",
        "plt.title(\"Label of the image: {}\".format(y_train[11]))\n",
        "\n",
        "plt.subplot(143)\n",
        "plt.imshow(X_train[12].reshape(28,28), cmap=\"gray\")\n",
        "plt.title(\"Label of the image: {}\".format(y_train[12]))\n",
        "\n",
        "plt.subplot(144)\n",
        "plt.imshow(X_train[13].reshape(28,28), cmap=\"gray\")\n",
        "plt.title(\"Label of the image: {}\".format(y_train[13]))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3-1u1IMLum_",
        "colab_type": "text"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em3bsAS2Of6l",
        "colab_type": "text"
      },
      "source": [
        "Let's start with a smaller NN like in the previous notebooks (expanding if necessary based on performance), and we will also begin with adjusting the activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kudLgcigHKeN",
        "outputId": "3c7ed3d3-0320-4909-c1e9-99380c71b6ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "# 3-layer ANN with 128, 64, 10, using tanh\n",
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"tanh\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"tanh\"))\n",
        "# our third dense layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training model\n",
        "model.fit(X_train, Y_train_hot, batch_size=batch_size, epochs=20, verbose=1)\n",
        "\n",
        "# Evaluating the model\n",
        "score = model.evaluate(X_test, Y_test_hot, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 1.0576 - accuracy: 0.6718\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.6675 - accuracy: 0.7840\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.5764 - accuracy: 0.8077\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.5295 - accuracy: 0.8196\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.5002 - accuracy: 0.8284\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4794 - accuracy: 0.8331\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4636 - accuracy: 0.8379\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4506 - accuracy: 0.8425\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4401 - accuracy: 0.8455\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4313 - accuracy: 0.8478\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4233 - accuracy: 0.8511\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4163 - accuracy: 0.8533\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4096 - accuracy: 0.8548\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4040 - accuracy: 0.8572\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3991 - accuracy: 0.8588\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3939 - accuracy: 0.8604\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3893 - accuracy: 0.8620\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3850 - accuracy: 0.8636\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3817 - accuracy: 0.8645\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3777 - accuracy: 0.8659\n",
            "Test score: 0.41576480865478516\n",
            "Test accuracy: 0.852400004863739\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "65465479-6c51-4666-87cc-67732d84f2df",
        "id": "5gve4LGzHKec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "# 3-layer ANN with 128, 64, 10, using relu\n",
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# our third dense layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training model\n",
        "model.fit(X_train, Y_train_hot, batch_size=batch_size, epochs=20, verbose=1)\n",
        "\n",
        "# Evaluating the model\n",
        "score = model.evaluate(X_test, Y_test_hot, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 1.1106 - accuracy: 0.6546\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.6522 - accuracy: 0.7839\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.5660 - accuracy: 0.8091\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.5215 - accuracy: 0.8220\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4965 - accuracy: 0.8278\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4767 - accuracy: 0.8346\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4625 - accuracy: 0.8390\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4501 - accuracy: 0.8436\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4401 - accuracy: 0.8472\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4323 - accuracy: 0.8500\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4256 - accuracy: 0.8523\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4188 - accuracy: 0.8541\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4135 - accuracy: 0.8564\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4081 - accuracy: 0.8584\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4028 - accuracy: 0.8596\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3987 - accuracy: 0.8625\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3933 - accuracy: 0.8634\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3904 - accuracy: 0.8641\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3853 - accuracy: 0.8662\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3821 - accuracy: 0.8667\n",
            "Test score: 0.42815810441970825\n",
            "Test accuracy: 0.848800003528595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cb7421ec-ec53-41c8-cd56-c5f0c02aa647",
        "id": "OLr7nEG1M0w3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "# 1. 3-layer ANN with 128, 64, 10, using leaky relu\n",
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,)))\n",
        "model.add(LeakyReLU(alpha=0.3))\n",
        "# our second dense layer\n",
        "model.add(Dense(64,))\n",
        "model.add(LeakyReLU(alpha=0.3))\n",
        "# our third dense layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='sgd', loss='categorical_hinge',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training the Model\n",
        "model.fit(X_train, Y_train_hot, batch_size=batch_size, epochs=20, verbose=1)\n",
        "\n",
        "# Evaluating the model\n",
        "score = model.evaluate(X_test, Y_test_hot, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.9976 - accuracy: 0.4184\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.8332 - accuracy: 0.6072\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.6773 - accuracy: 0.6760\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.5994 - accuracy: 0.7089\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.5477 - accuracy: 0.7560\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4999 - accuracy: 0.7857\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4625 - accuracy: 0.7967\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4357 - accuracy: 0.8054\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4165 - accuracy: 0.8107\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4012 - accuracy: 0.8166\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3891 - accuracy: 0.8217\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3793 - accuracy: 0.8257\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3709 - accuracy: 0.8282\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3636 - accuracy: 0.8320\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3573 - accuracy: 0.8329\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3518 - accuracy: 0.8361\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3473 - accuracy: 0.8372\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3424 - accuracy: 0.8397\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3385 - accuracy: 0.8411\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3347 - accuracy: 0.8429\n",
            "Test score: 0.35439762473106384\n",
            "Test accuracy: 0.8295000195503235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9ZjpsapYJV0",
        "colab_type": "text"
      },
      "source": [
        "The ReLU activation function appears to work best.\n",
        "\n",
        "---\n",
        "<br></br>\n",
        "## Loss Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c4c557e7-96b5-458a-f348-e15f391d3513",
        "id": "_e2V1_zrM0w_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "# 3-layer ANN with 128, 64, 10, using relu and hinge loss\n",
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# our third dense layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='sgd', loss='categorical_hinge',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training model\n",
        "model.fit(X_train, Y_train_hot, batch_size=batch_size, epochs=20, verbose=1)\n",
        "\n",
        "# Evaluating the model\n",
        "score = model.evaluate(X_test, Y_test_hot, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 1.0004 - accuracy: 0.3818\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.8989 - accuracy: 0.5468\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.7496 - accuracy: 0.6316\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.6552 - accuracy: 0.6908\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5933 - accuracy: 0.7356\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5395 - accuracy: 0.7658\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4946 - accuracy: 0.7855\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4616 - accuracy: 0.7981\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4371 - accuracy: 0.8059\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4178 - accuracy: 0.8125\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4027 - accuracy: 0.8172\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3905 - accuracy: 0.8206\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3803 - accuracy: 0.8253\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3716 - accuracy: 0.8280\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3641 - accuracy: 0.8310\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3576 - accuracy: 0.8334\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3515 - accuracy: 0.8358\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3469 - accuracy: 0.8375\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3423 - accuracy: 0.8393\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3380 - accuracy: 0.8416\n",
            "Test score: 0.3577786684036255\n",
            "Test accuracy: 0.8281999826431274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpauDZtpZCus",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "fcd4098b-9dd2-4a4a-c0bf-f157a70441ae"
      },
      "source": [
        "# 3-layer ANN with 128, 64, 10, using relu and SparseCategoricalCrossentropy\n",
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# our third dense layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='sgd', loss=losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training model\n",
        "model.fit(X_train, y_train, epochs=20, verbose=1)\n",
        "\n",
        "# Evaluating the model\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.7317 - accuracy: 0.7596\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4953 - accuracy: 0.8257\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4499 - accuracy: 0.8423\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4232 - accuracy: 0.8513\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4044 - accuracy: 0.8577\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3887 - accuracy: 0.8630\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3763 - accuracy: 0.8679\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3646 - accuracy: 0.8715\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3528 - accuracy: 0.8748\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3444 - accuracy: 0.8783\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3366 - accuracy: 0.8802\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3278 - accuracy: 0.8841\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3215 - accuracy: 0.8855\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3155 - accuracy: 0.8883\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3092 - accuracy: 0.8899\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3036 - accuracy: 0.8911\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2969 - accuracy: 0.8928\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2930 - accuracy: 0.8956\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2885 - accuracy: 0.8966\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2827 - accuracy: 0.8982\n",
            "Test score: 0.3552650511264801\n",
            "Test accuracy: 0.8740000128746033\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3Ktuo_Ld2t_",
        "colab_type": "text"
      },
      "source": [
        "Sparse Categorical Crossentropy is the best performing loss function.\n",
        "\n",
        "---\n",
        "<br></br>\n",
        "# Batch Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho5dIDhdiu4r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "20a36f48-e795-4658-a2d4-637b1b8b11ea"
      },
      "source": [
        "# 3-layer ANN with 128, 64, 10, using relu, SparseCategoricalCrossentropy, and batch size 64\n",
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# our third dense layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='sgd', loss=losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training model\n",
        "model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\n",
        "\n",
        "# Evaluating the model\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 1.2067 - accuracy: 0.6189\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.6912 - accuracy: 0.7698\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.5930 - accuracy: 0.8011\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.5443 - accuracy: 0.8154\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.5131 - accuracy: 0.8245\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4935 - accuracy: 0.8296\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4763 - accuracy: 0.8351\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4653 - accuracy: 0.8379\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4539 - accuracy: 0.8424\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4447 - accuracy: 0.8453\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4354 - accuracy: 0.8490\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4292 - accuracy: 0.8515\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4220 - accuracy: 0.8535\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4151 - accuracy: 0.8562\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4103 - accuracy: 0.8580\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4046 - accuracy: 0.8589\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3999 - accuracy: 0.8607\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3944 - accuracy: 0.8620\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3896 - accuracy: 0.8640\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3860 - accuracy: 0.8667\n",
            "Test score: 0.4267398416996002\n",
            "Test accuracy: 0.8485000133514404\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkdgWnMth7eh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "801e497f-7e0a-40e8-e810-d19d27fcd1a0"
      },
      "source": [
        "# 3-layer ANN with 128, 64, 10, using relu, SparseCategoricalCrossentropy, and batch size 64\n",
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# our third dense layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='sgd', loss=losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training model\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=20, verbose=1)\n",
        "\n",
        "# Evaluating the model\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.8944 - accuracy: 0.7171\n",
            "Epoch 2/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.5535 - accuracy: 0.8108\n",
            "Epoch 3/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.4959 - accuracy: 0.8281\n",
            "Epoch 4/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.4652 - accuracy: 0.8391\n",
            "Epoch 5/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.4451 - accuracy: 0.8448\n",
            "Epoch 6/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.4285 - accuracy: 0.8500\n",
            "Epoch 7/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.4164 - accuracy: 0.8537\n",
            "Epoch 8/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.4039 - accuracy: 0.8584\n",
            "Epoch 9/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3938 - accuracy: 0.8617\n",
            "Epoch 10/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3858 - accuracy: 0.8652\n",
            "Epoch 11/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3779 - accuracy: 0.8686\n",
            "Epoch 12/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3699 - accuracy: 0.8709\n",
            "Epoch 13/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3638 - accuracy: 0.8717\n",
            "Epoch 14/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3573 - accuracy: 0.8751\n",
            "Epoch 15/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3522 - accuracy: 0.8757\n",
            "Epoch 16/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3471 - accuracy: 0.8775\n",
            "Epoch 17/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3412 - accuracy: 0.8796\n",
            "Epoch 18/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3365 - accuracy: 0.8818\n",
            "Epoch 19/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3318 - accuracy: 0.8826\n",
            "Epoch 20/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3277 - accuracy: 0.8840\n",
            "Test score: 0.3999037742614746\n",
            "Test accuracy: 0.8550000190734863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ammQa6Xni-rG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "7927d871-562d-4de7-fc6f-714947a39a8d"
      },
      "source": [
        "# 3-layer ANN with 128, 64, 10, using relu, SparseCategoricalCrossentropy, and batch size 16\n",
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# our third dense layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='sgd', loss=losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training model\n",
        "model.fit(X_train, y_train, batch_size=16, epochs=20, verbose=1)\n",
        "\n",
        "# Evaluating the model\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.6266 - accuracy: 0.7856\n",
            "Epoch 2/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.4461 - accuracy: 0.8439\n",
            "Epoch 3/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.4017 - accuracy: 0.8563\n",
            "Epoch 4/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.3753 - accuracy: 0.8653\n",
            "Epoch 5/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.3566 - accuracy: 0.8712\n",
            "Epoch 6/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.3411 - accuracy: 0.8775\n",
            "Epoch 7/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.3274 - accuracy: 0.8818\n",
            "Epoch 8/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.3169 - accuracy: 0.8848\n",
            "Epoch 9/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.3074 - accuracy: 0.8897\n",
            "Epoch 10/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2986 - accuracy: 0.8913\n",
            "Epoch 11/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2904 - accuracy: 0.8932\n",
            "Epoch 12/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2829 - accuracy: 0.8971\n",
            "Epoch 13/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2753 - accuracy: 0.8996\n",
            "Epoch 14/20\n",
            "3750/3750 [==============================] - 7s 2ms/step - loss: 0.2694 - accuracy: 0.9004\n",
            "Epoch 15/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2633 - accuracy: 0.9033\n",
            "Epoch 16/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2577 - accuracy: 0.9058\n",
            "Epoch 17/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2528 - accuracy: 0.9071\n",
            "Epoch 18/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2468 - accuracy: 0.9092\n",
            "Epoch 19/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2428 - accuracy: 0.9104\n",
            "Epoch 20/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2377 - accuracy: 0.9125\n",
            "Test score: 0.3368183672428131\n",
            "Test accuracy: 0.880299985408783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5eI9ZtBh3bY",
        "colab_type": "text"
      },
      "source": [
        "# Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv8pkzMEhXh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd_01 = optimizers.SGD(lr=0.1)\n",
        "sgd_001 = optimizers.SGD(lr=0.01)\n",
        "sgd_0001 = optimizers.SGD(lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HCQbdX-9d9Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "dc48b11f-7179-4519-936e-bec98dd8bf89"
      },
      "source": [
        "# 3-layer ANN with 128, 64, 10, using relu, SparseCategoricalCrossentropy, batch size 16, learning rate .1\n",
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# our third dense layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer=sgd_01, loss=losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training model\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=20, verbose=1)\n",
        "\n",
        "# Evaluating the model\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.5852 - accuracy: 0.7897\n",
            "Epoch 2/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.4135 - accuracy: 0.8490\n",
            "Epoch 3/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3718 - accuracy: 0.8634\n",
            "Epoch 4/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3448 - accuracy: 0.8745\n",
            "Epoch 5/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3252 - accuracy: 0.8796\n",
            "Epoch 6/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3088 - accuracy: 0.8856\n",
            "Epoch 7/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2970 - accuracy: 0.8909\n",
            "Epoch 8/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2853 - accuracy: 0.8946\n",
            "Epoch 9/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2768 - accuracy: 0.8977\n",
            "Epoch 10/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2660 - accuracy: 0.9010\n",
            "Epoch 11/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2598 - accuracy: 0.9037\n",
            "Epoch 12/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2510 - accuracy: 0.9051\n",
            "Epoch 13/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2453 - accuracy: 0.9077\n",
            "Epoch 14/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2407 - accuracy: 0.9094\n",
            "Epoch 15/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2322 - accuracy: 0.9114\n",
            "Epoch 16/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2282 - accuracy: 0.9138\n",
            "Epoch 17/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2231 - accuracy: 0.9176\n",
            "Epoch 18/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2169 - accuracy: 0.9196\n",
            "Epoch 19/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2121 - accuracy: 0.9204\n",
            "Epoch 20/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2068 - accuracy: 0.9223\n",
            "Test score: 0.3483850955963135\n",
            "Test accuracy: 0.8801000118255615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu_XgdhLk53A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "1049e639-186e-4c87-d9c2-9eab987afb4e"
      },
      "source": [
        "# 3-layer ANN with 128, 64, 10, using relu, SparseCategoricalCrossentropy, batch size 16, learning rate .01\n",
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# our third dense layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer=sgd_001, loss=losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training model\n",
        "model.fit(X_train, y_train, batch_size=16, epochs=20, verbose=1)\n",
        "\n",
        "# Evaluating the model\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.6269 - accuracy: 0.7865\n",
            "Epoch 2/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.4489 - accuracy: 0.8424\n",
            "Epoch 3/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.4049 - accuracy: 0.8570\n",
            "Epoch 4/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.3783 - accuracy: 0.8658\n",
            "Epoch 5/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.3601 - accuracy: 0.8716\n",
            "Epoch 6/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.3439 - accuracy: 0.8771\n",
            "Epoch 7/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.3299 - accuracy: 0.8804\n",
            "Epoch 8/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.3194 - accuracy: 0.8844\n",
            "Epoch 9/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.3090 - accuracy: 0.8881\n",
            "Epoch 10/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.3006 - accuracy: 0.8914\n",
            "Epoch 11/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2926 - accuracy: 0.8939\n",
            "Epoch 12/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2842 - accuracy: 0.8963\n",
            "Epoch 13/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2778 - accuracy: 0.8984\n",
            "Epoch 14/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2700 - accuracy: 0.9014\n",
            "Epoch 15/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2644 - accuracy: 0.9032\n",
            "Epoch 16/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2595 - accuracy: 0.9043\n",
            "Epoch 17/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2534 - accuracy: 0.9075\n",
            "Epoch 18/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2482 - accuracy: 0.9085\n",
            "Epoch 19/20\n",
            "3750/3750 [==============================] - 7s 2ms/step - loss: 0.2428 - accuracy: 0.9106\n",
            "Epoch 20/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2387 - accuracy: 0.9123\n",
            "Test score: 0.3297843933105469\n",
            "Test accuracy: 0.8873000144958496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAf1_ck7k892",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "58f7c654-b09c-4fb7-f8ca-22d4c5f83bcc"
      },
      "source": [
        "# 3-layer ANN with 128, 64, 10, using relu, SparseCategoricalCrossentropy, batch size 16, learning rate .001\n",
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# our third dense layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer=sgd_0001, loss=losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training model\n",
        "model.fit(X_train, y_train, batch_size=16, epochs=20, verbose=1)\n",
        "\n",
        "# Evaluating the model\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2684 - accuracy: 0.6096\n",
            "Epoch 2/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.7218 - accuracy: 0.7623\n",
            "Epoch 3/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.6115 - accuracy: 0.7979\n",
            "Epoch 4/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.5563 - accuracy: 0.8136\n",
            "Epoch 5/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.5224 - accuracy: 0.8237\n",
            "Epoch 6/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.4993 - accuracy: 0.8286\n",
            "Epoch 7/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.4818 - accuracy: 0.8341\n",
            "Epoch 8/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.4687 - accuracy: 0.8381\n",
            "Epoch 9/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.4583 - accuracy: 0.8408\n",
            "Epoch 10/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.4496 - accuracy: 0.8439\n",
            "Epoch 11/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.4412 - accuracy: 0.8471\n",
            "Epoch 12/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.4345 - accuracy: 0.8493\n",
            "Epoch 13/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.4284 - accuracy: 0.8516\n",
            "Epoch 14/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.4225 - accuracy: 0.8523\n",
            "Epoch 15/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.4170 - accuracy: 0.8557\n",
            "Epoch 16/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.4123 - accuracy: 0.8575\n",
            "Epoch 17/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.4074 - accuracy: 0.8591\n",
            "Epoch 18/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.4032 - accuracy: 0.8605\n",
            "Epoch 19/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.3995 - accuracy: 0.8615\n",
            "Epoch 20/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.3959 - accuracy: 0.8627\n",
            "Test score: 0.4308266043663025\n",
            "Test accuracy: 0.8485000133514404\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZPWSFcxqr4W",
        "colab_type": "text"
      },
      "source": [
        "A learning rate of 0.01 seems to be optimum\n",
        "\n",
        "---\n",
        "\n",
        "# Layers\n",
        "\n",
        "Let's see if a reduction or increase in layers improves the performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXSU3IKQqqvw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "b39e493c-06ad-4fd2-ed30-a2020991ce66"
      },
      "source": [
        "# 2-layer ANN with 128,, 10, using relu, SparseCategoricalCrossentropy, batch size 16, learning rate .1\n",
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer=sgd_001, loss=losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training model\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=20, verbose=1)\n",
        "\n",
        "# Evaluating the model\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.8909 - accuracy: 0.7243\n",
            "Epoch 2/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.5827 - accuracy: 0.8077\n",
            "Epoch 3/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.5224 - accuracy: 0.8250\n",
            "Epoch 4/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.4903 - accuracy: 0.8334\n",
            "Epoch 5/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.4690 - accuracy: 0.8389\n",
            "Epoch 6/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.4528 - accuracy: 0.8447\n",
            "Epoch 7/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.4403 - accuracy: 0.8489\n",
            "Epoch 8/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.4300 - accuracy: 0.8516\n",
            "Epoch 9/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.4212 - accuracy: 0.8545\n",
            "Epoch 10/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.4135 - accuracy: 0.8573\n",
            "Epoch 11/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.4058 - accuracy: 0.8606\n",
            "Epoch 12/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3997 - accuracy: 0.8616\n",
            "Epoch 13/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3946 - accuracy: 0.8628\n",
            "Epoch 14/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3881 - accuracy: 0.8661\n",
            "Epoch 15/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3834 - accuracy: 0.8662\n",
            "Epoch 16/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3790 - accuracy: 0.8689\n",
            "Epoch 17/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3742 - accuracy: 0.8696\n",
            "Epoch 18/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3701 - accuracy: 0.8717\n",
            "Epoch 19/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3663 - accuracy: 0.8728\n",
            "Epoch 20/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3630 - accuracy: 0.8736\n",
            "Test score: 0.4005228877067566\n",
            "Test accuracy: 0.8593999743461609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNaj7dmWt1Jx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "5013f054-37f2-48b7-bf32-b9a89c3e04de"
      },
      "source": [
        "# 4-layer ANN with 1280,128,64, 10, using relu, SparseCategoricalCrossentropy, batch size 16, learning rate .1\n",
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(1280, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# third dense layer\n",
        "model.add(Dense(64, input_shape=(784,), activation=\"relu\"))\n",
        "# fourth dense layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer=sgd_001, loss=losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training model\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=20, verbose=1)\n",
        "\n",
        "# Evaluating the model\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 0.8072 - accuracy: 0.7388\n",
            "Epoch 2/20\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.5069 - accuracy: 0.8229\n",
            "Epoch 3/20\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.4569 - accuracy: 0.8399\n",
            "Epoch 4/20\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.4282 - accuracy: 0.8500\n",
            "Epoch 5/20\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.4057 - accuracy: 0.8579\n",
            "Epoch 6/20\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.3891 - accuracy: 0.8646\n",
            "Epoch 7/20\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.3748 - accuracy: 0.8684\n",
            "Epoch 8/20\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.3626 - accuracy: 0.8724\n",
            "Epoch 9/20\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.3513 - accuracy: 0.8756\n",
            "Epoch 10/20\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.3426 - accuracy: 0.8785\n",
            "Epoch 11/20\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.3329 - accuracy: 0.8812\n",
            "Epoch 12/20\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.3236 - accuracy: 0.8856\n",
            "Epoch 13/20\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.3177 - accuracy: 0.8868\n",
            "Epoch 14/20\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.3090 - accuracy: 0.8895\n",
            "Epoch 15/20\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.3020 - accuracy: 0.8913\n",
            "Epoch 16/20\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.2966 - accuracy: 0.8935\n",
            "Epoch 17/20\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.2891 - accuracy: 0.8960\n",
            "Epoch 18/20\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.2845 - accuracy: 0.8974\n",
            "Epoch 19/20\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.2775 - accuracy: 0.9010\n",
            "Epoch 20/20\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.2724 - accuracy: 0.9016\n",
            "Test score: 0.3352808356285095\n",
            "Test accuracy: 0.8812999725341797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGzUI-THSi-B",
        "colab_type": "text"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "The best performing algorithm looks to be 3-layer ANN with 128, 64, 10, using relu, SparseCategoricalCrossentropy, learning rate .01, and batch size 16\n",
        "\n",
        "\n"
      ]
    }
  ]
}